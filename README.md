# Awesome-Visual-Tokenizer

- [Image Autoencoders](#image-autoencoders)
  - [Continuous 2D CNN Image Autoencoder](#continuous-2d-cnn-image-autoencoder)
  - [Discrete 2D CNN Image Autoencoder](#discrete-2d-cnn-image-autoencoder)
  - [2D Transformer Image Autoencoder](#2d-transformer-image-autoencoder)
  - [1D Image Autoencoder](#1d-image-autoencoder)
  - [Image Autoencoder with Generative Decoder](#image-autoencoder-with-generative-decoder)
- [Video Autoencoders](#video-autoencoders)
  - [Continuous 3D CNN Video Autoencoder](#continuous-3d-cnn-video-autoencoder)
  - [Discrete 3D CNN Video Autoencoder](#discrete-3d-cnn-video-autoencoder)
  - [3D Transformer Video Autoencoder](#3d-transformer-video-autoencoder)
  - [1D Video Autoencoder](#1d-video-autoencoder)
  - [Video Autoencoder with Generative Decoder](#video-autoencoder-with-generative-decoder)

## Image Autoencoders

### Continuous 2D CNN Image Autoencoder
- Dai, B. & Wipf, D. (2019). **Diagnosing and enhancing VAE models**. *arXiv preprint arXiv:1903.05789*.
- Chen, J., Cai, H., Chen, J. et al. (2024). **Deep compression autoencoder for efficient high-resolution diffusion models**. *arXiv preprint arXiv:2410.10733*.
- Chen, J., Zou, D., He, W. et al. (2025). **DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space**. *arXiv preprint arXiv:2508.00413*.


### Discrete 2D CNN Image Autoencoder

- Esser, P., Rombach, R. & Ommer, B. (2021). **Taming transformers for high-resolution image synthesis**. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 12873–12883).
- Lee, D., Kim, C., Kim, S. et al. (2022). **Autoregressive image generation using residual quantization**. In *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition* (pp. 11523–11532).
- Mentzer, F., Minnen, D., Agustsson, E. et al. (2023). **Finite scalar quantization: Vq-vae made simple**. *arXiv preprint arXiv:2309.15505*.
- Yu, L., Lezama, J., Gundavarapu, N.B. et al. (2023). **Language Model Beats Diffusion--Tokenizer is Key to Visual Generation**. *arXiv preprint arXiv:2310.05737*.
- Yu, L., Cheng, Y., Sohn, K. et al. (2023). **Magvit: Masked generative video transformer**. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition* (pp. 10459–10469).
- BAAI, E.T. (2024). **Emu3: Next-Token Prediction is All You Need**.
- Tian, K., Jiang, Y., Yuan, Z. et al. (2024). **Visual autoregressive modeling: Scalable image generation via next-scale prediction**. *arXiv preprint arXiv:2404.02905*.
- Sun, P., Jiang, Y., Chen, S. et al. (2024). **Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation**. *arXiv preprint arXiv:2406.06525*.
- Luo, Z., Shi, F., Ge, Y. et al. (2024). **Open-magvit2: An open-source project toward democratizing auto-regressive visual generation**. *arXiv preprint arXiv:2409.04410*.
- Zhang, B., Rao, Q., Zheng, W. et al. (2025). **Quantize-then-Rectify: Efficient VQ-VAE Training**. *arXiv preprint arXiv:2507.10547*.
- Zhao, Y., Xiong, Y. & Kr{\"a}henb{\"u}hl, P. (2024). **Image and video tokenization with binary spherical quantization**. *arXiv preprint arXiv:2406.07548*.
- Wang, W., Zhang, F., Cui, Y. et al. (2025). **End-to-end vision tokenizer tuning**. *arXiv preprint arXiv:2505.10562*.


### 2D Transformer Image Autoencoder

- Zheng, A., Wen, X., Zhang, X. et al. (2025). **Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation**. *arXiv preprint arXiv:2507.08441*.
- Hansen-Estruch, P., Yan, D., Chung, C. et al. (2025). **Learnings from scaling visual tokenizers for reconstruction and generation**. *arXiv preprint arXiv:2501.09755*.
- Li, Y., Qian, R., Pan, B. et al. (2025). **MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer**.
- Ma, C., Jiang, Y., Wu, J. et al. (2025). **Unitok: A unified tokenizer for visual generation and understanding**. *arXiv preprint arXiv:2502.20321*.
- Sim{\'e}oni, O., Vo, H.V., Seitzer, M. et al. (2025). **Dinov3**. *arXiv preprint arXiv:2508.10104*.
- Tang, H., Xie, C., Bao, X. et al. (2025). **UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing**. *arXiv preprint arXiv:2507.23278*.
- Xiong, T., Liew, J.H., Huang, Z. et al. (2025). **Gigatok: Scaling visual tokenizers to 3 billion parameters for autoregressive image generation**. *arXiv preprint arXiv:2504.08736*.
- Shi, M., Wang, H., Zheng, W. et al. (2025). **Latent Diffusion Model without Variational Autoencoder**. *arXiv preprint arXiv:2510.15301*.
- Zheng, B., Ma, N., Tong, S. et al. (2025). **Diffusion Transformers with Representation Autoencoders**. *arXiv preprint arXiv:2510.11690*.
- Chen, B., Bi, S., Tan, H. et al. (2025). **Aligning Visual Foundation Encoders to Tokenizers for Diffusion Models**.

### 1D Image Autoencoder

- Yu, Q., Weber, M., Deng, X. et al. (2024). **An image is worth 32 tokens for reconstruction and generation**. *Advances in Neural Information Processing Systems* **37** : 128940–128966.
- Yan, W., Mnih, V., Faust, A. et al. (2024). **Elastictok: Adaptive tokenization for image and video**. *arXiv preprint arXiv:2410.08368*.
- Yang, J., Li, T., Fan, L. et al. (2025). **Latent Denoising Makes Good Visual Tokenizers**. *arXiv preprint arXiv:2507.15856*.
- Zha, K., Yu, L., Fathi, A. et al. (2025). **Language-guided image tokenization for generation**. In *Proceedings of the Computer Vision and Pattern Recognition Conference* (pp. 15713–15722).
- Beyer, L.L., Li, T., Chen, X. et al. (2025). **Highly Compressed Tokenizer Can Generate Without Training**. *arXiv preprint arXiv:2506.08257*.
- Chen, H., Han, Y., Chen, F. et al. (2025). **Masked autoencoders are effective tokenizers for diffusion models**. In *Forty-second International Conference on Machine Learning*.
- Chen, H., Wang, Z., Li, X. et al. (2025). **Softvq-vae: Efficient 1-dimensional continuous tokenizer**. In *Proceedings of the Computer Vision and Pattern Recognition Conference* (pp. 28358–28370).
- Duggal, S., Isola, P., Torralba, A. et al. (2024). **Adaptive length image tokenization via recurrent allocation**. In *First Workshop on Scalable Optimization for Efficient and Adaptive Foundation Models*.
- Kim, D., He, J., Yu, Q. et al. (2025). **Democratizing text-to-image masked generative models with compact text-aware one-dimensional tokens**. *arXiv preprint arXiv:2501.07730*.
- Bachmann, R., Allardice, J., Mizrahi, D. et al. (2025). **FlexTok: Resampling Images into 1D Token Sequences of Flexible Length**. In *Forty-second International Conference on Machine Learning*.
- Xiong, T., Liew, J.H., Huang, Z. et al. (2025). **Gigatok: Scaling visual tokenizers to 3 billion parameters for autoregressive image generation**. *arXiv preprint arXiv:2504.08736*.
- Liu, Y., Qu, L., Zhang, H. et al. (2025). **DetailFlow: 1D Coarse-to-Fine Autoregressive Image Generation via Next-Detail Prediction**. *arXiv preprint arXiv:2505.21473*.
- Miwa, K., Sasaki, K., Arai, H. et al. (2025). **One-d-piece: Image tokenizer meets quality-controllable compression**. *arXiv preprint arXiv:2501.10064*.
- Qiu, K., Li, X., Chen, H. et al. (2025). **Image Tokenizer Needs Post-Training**. *arXiv preprint arXiv:2509.12474*.
- Wu, P., Zhu, K., Liu, Y. et al. (2025). **AliTok: Towards Sequence Modeling Alignment between Tokenizer and Autoregressive Model**. *arXiv preprint arXiv:2506.05289*.


### Image Autoencoder with Generative Decoder

- Zhao, L., Woo, S., Wan, Z. et al. (2024). **epsilon-vae: Denoising as visual decoding**. *arXiv preprint arXiv:2410.04081*.
- Chen, Y., Girdhar, R., Wang, X. et al. (2025). **Diffusion autoencoders are scalable image tokenizers**. *arXiv preprint arXiv:2501.18593*.
- Bachmann, R., Allardice, J., Mizrahi, D. et al. (2025). **FlexTok: Resampling Images into 1D Token Sequences of Flexible Length**. In *Forty-second International Conference on Machine Learning*.
- Gao, Z. & Shou, M.Z. (2025). **D-AR: Diffusion via Autoregressive Models**. *arXiv preprint arXiv:2505.23660*.
- Pan, K., Lin, W., Yue, Z. et al. (2025). **Generative Multimodal Pretraining with Discrete Diffusion Timestep Tokens**. In *Proceedings of the Computer Vision and Pattern Recognition Conference* (pp. 26136–26146).
- Sargent, K., Hsu, K., Johnson, J. et al. (2025). **Flow to the mode: Mode-seeking diffusion autoencoders for state-of-the-art image tokenization**. *arXiv preprint arXiv:2503.11056*.
- Wen, X., Zhao, B., Elezi, I. et al. (2025). **" Principal Components" Enable A New Language of Images**. *arXiv preprint arXiv:2503.08685*.



## Video Autoencoders

### Continuous 3D CNN Video Autoencoder

- Brooks, T., Peebles, B., Holmes, C. et al. (2024). **Video generation models as world simulators**. **.
- Yang, Z., Teng, J., Zheng, W. et al. (2024). **Cogvideox: Text-to-video diffusion models with an expert transformer**. *arXiv preprint arXiv:2408.06072*.
- Lin, B., Ge, Y., Cheng, X. et al. (2024). **Open-sora plan: Open-source large video generation model**. *arXiv preprint arXiv:2412.00131*.
- Kong, W., Tian, Q., Zhang, Z. et al. (2024). **Hunyuanvideo: A systematic framework for large video generative models**. *arXiv preprint arXiv:2412.03603*.
- Wan, T., Wang, A., Ai, B. et al. (2025). **Wan: Open and advanced large-scale video generative models**. *arXiv preprint arXiv:2503.20314*.
- HaCohen, Y., Chiprut, N., Brazowski, B. et al. (2024). **Ltx-video: Realtime video latent diffusion**. *arXiv preprint arXiv:2501.00103*.
- Agarwal, N., Ali, A., Bala, M. et al. (2025). **Cosmos world foundation model platform for physical ai**. *arXiv preprint arXiv:2501.03575*.
- Cheng, Y. & Yuan, F. (2025). **LeanVAE: An Ultra-Efficient Reconstruction VAE for Video Diffusion Models**. *arXiv preprint arXiv:2503.14325*.
- Li, Z., Lin, B., Ye, Y. et al. (2025). **Wf-vae: Enhancing video vae by wavelet-driven energy flow for latent video diffusion model**. In *Proceedings of the Computer Vision and Pattern Recognition Conference* (pp. 17778–17788).
- Ma, G., Huang, H., Yan, K. et al. (2025). **Step-video-t2v technical report: The practice, challenges, and future of video foundation model**. *arXiv preprint arXiv:2502.10248*.
- Zhang, Y., Yang, H., Zhang, Y. et al. (2025). **Waver: Wave Your Way to Lifelike Video Generation**. *arXiv preprint arXiv:2508.15761*.
- Wang, Y., Guo, J., Xie, X. et al. (2025). **Vidtwin: Video vae with decoupled structure and dynamics**. In *Proceedings of the Computer Vision and Pattern Recognition Conference* (pp. 22922–22932).

### Discrete 3D CNN Video Autoencoder

- Yu, L., Lezama, J., Gundavarapu, N.B. et al. (2023). **Language Model Beats Diffusion--Tokenizer is Key to Visual Generation**. *arXiv preprint arXiv:2310.05737*.
- Kondratyuk, D., Yu, L., Gu, X. et al. (2023). **Videopoet: A large language model for zero-shot video generation**. *arXiv preprint arXiv:2312.14125*.
- Wang, Y., Xiong, T., Zhou, D. et al. (2024). **Loong: Generating minute-level long videos with autoregressive language models**. *arXiv preprint arXiv:2410.02757*.
- Tang, A., He, T., Guo, J. et al. (2024). **Vidtok: A versatile and open-source video tokenizer**. *arXiv preprint arXiv:2412.13061*.
- Wang, J., Jiang, Y., Yuan, Z. et al. (2024). **Omnitokenizer: A joint image-video tokenizer for visual generation**. *Advances in Neural Information Processing Systems* **37** : 28281–28295.
- Agarwal, N., Ali, A., Bala, M. et al. (2025). **Cosmos world foundation model platform for physical ai**. *arXiv preprint arXiv:2501.03575*.


### 3D Transformer Video Autoencoder

- Teng, H., Jia, H., Sun, L. et al. (2025). **MAGI-1: Autoregressive Video Generation at Scale**. *arXiv preprint arXiv:2505.13211*.
- Lu, J., Song, L., Xu, M. et al. (2025). **AToken: A Unified Tokenizer for Vision**. *arXiv preprint arXiv:2509.14476*.
- Liu, H., Sun, W., Zhang, Q. et al. (2025). **Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion**. *arXiv preprint arXiv:2506.07136*.

### 1D Video Autoencoder

- Wang, H., Suri, S., Ren, Y. et al. (2024). **Larp: Tokenizing videos with a learned autoregressive generative prior**. *arXiv preprint arXiv:2410.21264*.
- Tao, C., Zhu, X., Su, S. et al. (2024). **Learning 1D causal visual representation with de-focus attention networks**. *Advances in Neural Information Processing Systems* **37** : 25913–25937.

### Video Autoencoder with Generative Decoder

- Yang, N., Li, P., Zhao, L. et al. (2025). **Rethinking video tokenization: A conditioned diffusion-based approach**. *arXiv preprint arXiv:2503.03708*.
- Zhang, Y., Mai, L., Mahapatra, A. et al. (2025). **REGEN: Learning Compact Video Embedding with (Re-) Generative Decoder**. *arXiv preprint arXiv:2503.08665*.
- Liu, H., Sun, W., Zhang, Q. et al. (2025). **Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion**. *arXiv preprint arXiv:2506.07136*.













